Search.setIndex({"alltitles": {"Contents:": [[2, null]], "Indices and tables": [[2, "indices-and-tables"]], "Module contents": [[0, "module-benchmarks"], [1, "module-contents"], [4, "module-modules"], [5, "module-tests"]], "Submodules": [[0, "submodules"], [1, "submodules"], [4, "submodules"], [5, "submodules"]], "Subpackages": [[0, "subpackages"]], "Welcome to llava-benchmark\u2019s documentation!": [[2, "welcome-to-llava-benchmark-s-documentation"]], "benchmarks package": [[0, "benchmarks-package"]], "benchmarks.benchmark module": [[0, "benchmarks-benchmark-module"]], "benchmarks.eval_rate_benchmark package": [[1, "benchmarks-eval-rate-benchmark-package"]], "benchmarks.eval_rate_benchmark.eval_rate_benchmark module": [[1, "benchmarks-eval-rate-benchmark-eval-rate-benchmark-module"]], "benchmarks.eval_rate_benchmark.eval_rate_plotter module": [[1, "benchmarks-eval-rate-benchmark-eval-rate-plotter-module"]], "benchmarks.eval_rate_benchmark.eval_rate_processor module": [[1, "module-benchmarks.eval_rate_benchmark.eval_rate_processor"]], "benchmarks.license_plate_benchmark module": [[0, "module-benchmarks.license_plate_benchmark"]], "llava_benchmark module": [[3, "llava-benchmark-module"]], "modules package": [[4, "modules-package"]], "modules.llava_benchmark module": [[4, "modules-llava-benchmark-module"]], "modules.ollama module": [[4, "modules-ollama-module"]], "tests package": [[5, "tests-package"]], "tests.test_benchmark module": [[5, "tests-test-benchmark-module"]], "tests.test_eval_rate_benchmark module": [[5, "tests-test-eval-rate-benchmark-module"]], "tests.test_license_plate_benchmark module": [[5, "tests-test-license-plate-benchmark-module"]]}, "docnames": ["benchmarks", "benchmarks.eval_rate_benchmark", "index", "llava_benchmark", "modules", "tests"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1}, "filenames": ["benchmarks.rst", "benchmarks.eval_rate_benchmark.rst", "index.rst", "llava_benchmark.rst", "modules.rst", "tests.rst"], "indexentries": {"average_eval_rates() (benchmarks.eval_rate_benchmark.eval_rate_processor.evalrateprocessor static method)": [[1, "benchmarks.eval_rate_benchmark.eval_rate_processor.EvalRateProcessor.average_eval_rates", false]], "benchmarks": [[0, "module-benchmarks", false]], "benchmarks.eval_rate_benchmark.eval_rate_processor": [[1, "module-benchmarks.eval_rate_benchmark.eval_rate_processor", false]], "benchmarks.license_plate_benchmark": [[0, "module-benchmarks.license_plate_benchmark", false]], "current_license_plate_number (benchmarks.license_plate_benchmark.licenseplatebenchmark attribute)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark.current_license_plate_number", false]], "evalrateprocessor (class in benchmarks.eval_rate_benchmark.eval_rate_processor)": [[1, "benchmarks.eval_rate_benchmark.eval_rate_processor.EvalRateProcessor", false]], "extract_license_plate_number() (benchmarks.license_plate_benchmark.licenseplatebenchmark method)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark.extract_license_plate_number", false]], "license_plate_numbers (benchmarks.license_plate_benchmark.licenseplatebenchmark attribute)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark.license_plate_numbers", false]], "licenseplatebenchmark (class in benchmarks.license_plate_benchmark)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark", false]], "media_file_path() (benchmarks.license_plate_benchmark.licenseplatebenchmark static method)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark.media_file_path", false]], "model_license_plate_numbers (benchmarks.license_plate_benchmark.licenseplatebenchmark attribute)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark.model_license_plate_numbers", false]], "module": [[0, "module-benchmarks", false], [0, "module-benchmarks.license_plate_benchmark", false], [1, "module-benchmarks.eval_rate_benchmark.eval_rate_processor", false], [4, "module-modules", false], [5, "module-tests", false]], "modules": [[4, "module-modules", false]], "process_eval_rate() (benchmarks.eval_rate_benchmark.eval_rate_processor.evalrateprocessor static method)": [[1, "benchmarks.eval_rate_benchmark.eval_rate_processor.EvalRateProcessor.process_eval_rate", false]], "process_license_plate_number() (benchmarks.license_plate_benchmark.licenseplatebenchmark method)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark.process_license_plate_number", false]], "store_license_plate() (benchmarks.license_plate_benchmark.licenseplatebenchmark method)": [[0, "benchmarks.license_plate_benchmark.LicensePlateBenchmark.store_license_plate", false]], "tests": [[5, "module-tests", false]]}, "objects": {"": [[0, 0, 0, "-", "benchmarks"], [4, 0, 0, "-", "modules"], [5, 0, 0, "-", "tests"]], "benchmarks": [[0, 0, 0, "-", "license_plate_benchmark"]], "benchmarks.eval_rate_benchmark": [[1, 0, 0, "-", "eval_rate_processor"]], "benchmarks.eval_rate_benchmark.eval_rate_processor": [[1, 1, 1, "", "EvalRateProcessor"]], "benchmarks.eval_rate_benchmark.eval_rate_processor.EvalRateProcessor": [[1, 2, 1, "", "average_eval_rates"], [1, 2, 1, "", "process_eval_rate"]], "benchmarks.license_plate_benchmark": [[0, 1, 1, "", "LicensePlateBenchmark"]], "benchmarks.license_plate_benchmark.LicensePlateBenchmark": [[0, 3, 1, "", "current_license_plate_number"], [0, 2, 1, "", "extract_license_plate_number"], [0, 3, 1, "", "license_plate_numbers"], [0, 2, 1, "", "media_file_path"], [0, 3, 1, "", "model_license_plate_numbers"], [0, 2, 1, "", "process_license_plate_number"], [0, 2, 1, "", "store_license_plate"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute"}, "terms": {"1": [0, 5], "A": 0, "If": 5, "In": [0, 5], "It": 0, "The": [0, 1], "These": 0, "__init__": [0, 5], "absolut": 0, "ar": [0, 5], "averag": 0, "average_eval_r": [0, 1], "base": [0, 1], "becaus": 5, "being": 0, "benchmark": 5, "benchmark_result": [0, 1], "calcul": 0, "call": 1, "class": [0, 1, 5], "command": 0, "contain": 0, "context": [0, 5], "correctli": 5, "creat": 0, "current": 0, "current_license_plate_numb": 0, "dict": 0, "directori": [0, 5], "enabl": 5, "eval_r": 1, "eval_rate_benchmark": 0, "eval_rate_plott": 0, "eval_rate_processor": 0, "evalratebenchmark": [0, 5], "evalrateprocessor": [0, 1], "evalu": [0, 1], "execut": 0, "extract": [0, 1], "extract_license_plate_numb": 0, "file": [0, 5], "found": 0, "from": [0, 1, 5], "get": 0, "ha": 0, "i": 0, "import": [0, 5], "index": 2, "instanc": 0, "licens": 0, "license_plate_benchmark": 2, "license_plate_numb": 0, "licenseplatebenchmark": [0, 5], "list": [0, 1], "llava_benchmark": [0, 2], "m": 5, "map": 0, "mark": [0, 5], "media": 0, "media_fil": 0, "media_file_path": 0, "method": 0, "model": 0, "model_license_plate_numb": 0, "modul": 2, "name": 0, "need": 5, "none": 0, "number": 0, "object": [0, 1], "ollama": 2, "option": 5, "output": 0, "packag": 2, "page": 2, "paramet": [0, 1], "path": 0, "plate": 0, "process": [0, 1], "process_eval_r": [0, 1], "process_license_plate_numb": 0, "project": [0, 5], "py": [0, 5], "pytest": 5, "python": [0, 5], "rate": [0, 1], "result": [0, 1], "return": [0, 1], "run": [0, 1, 5], "script": 0, "search": 2, "sourc": [0, 1], "specif": 0, "standard": 0, "static": [0, 1], "stdout": 0, "store": 0, "store_license_pl": 0, "str": 0, "submodul": 2, "subpackag": 2, "subprocess": [0, 1], "thi": [0, 5], "two": 0, "type": [0, 1], "us": 0, "usag": 0, "work": 5}, "titles": ["benchmarks package", "benchmarks.eval_rate_benchmark package", "Welcome to llava-benchmark\u2019s documentation!", "llava_benchmark module", "modules package", "tests package"], "titleterms": {"": 2, "benchmark": [0, 1, 2], "content": [0, 1, 2, 4, 5], "document": 2, "eval_rate_benchmark": 1, "eval_rate_plott": 1, "eval_rate_processor": 1, "indic": 2, "license_plate_benchmark": 0, "llava": 2, "llava_benchmark": [3, 4], "modul": [0, 1, 3, 4, 5], "ollama": 4, "packag": [0, 1, 4, 5], "submodul": [0, 1, 4, 5], "subpackag": 0, "tabl": 2, "test": 5, "test_benchmark": 5, "test_eval_rate_benchmark": 5, "test_license_plate_benchmark": 5, "welcom": 2}})